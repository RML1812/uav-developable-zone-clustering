{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuRXyKCxniOI"
      },
      "source": [
        "# UAV Developable Zone Clustering: Processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is made to do processing for UAV data that collected from public source. The process will include:\n",
        "---\n",
        "\n",
        "1.   Data Collection\n",
        "2.   Preprocessing Data\n",
        "3.   Feature Extraction\n",
        "4.   Modeling\n",
        "5.   Implementation\n",
        "---\n",
        "\n",
        "The goals for this process is to cluster data based on:\n",
        "---\n",
        "\n",
        "1.   Developable area for plants\n",
        "2.   Developable area for constructions\n",
        "3.   Developable area for both plants and constrcutions\n",
        "4.   Non-developable area (already balanced)\n",
        "\n",
        "**this notebook is made in Google Colab while intergrated with Github, it will be better to run this notebook on the same space.*"
      ],
      "metadata": {
        "id": "PSHBhDLPozGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Library"
      ],
      "metadata": {
        "id": "mAbWtwnR8wOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib numpy Pillow opencv-python scikit-image scikit-learn joblib"
      ],
      "metadata": {
        "id": "w7QJpLuGFir6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import joblib\n",
        "from PIL import Image\n",
        "from skimage import color, filters, measure, morphology\n",
        "from skimage.feature import canny\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.morphology import closing, square\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "NvjhOQqA8uuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection"
      ],
      "metadata": {
        "id": "mFV1Dvn8r3dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data that will be used comes from kaggle, the dataset is available to download at https://www.kaggle.com/datasets/ankit1743/skyview-an-aerial-landscape-dataset (also available in this repo as Aerial_Landscapes.zip)."
      ],
      "metadata": {
        "id": "tf620hQ6r8nK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Unzip"
      ],
      "metadata": {
        "id": "fc1Cjczz6eQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from github repo\n",
        "!wget https://github.com/RML1812/uav-developable-zone-clustering/raw/refs/heads/main/Aerial_Landscapes.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lhdBPSJTplcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip to /data folder\n",
        "!unzip /content/Aerial_Landscapes.zip -d /content/data/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "m0MiworK54Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read directory of data and total image in each folder\n",
        "data_dir = '/content/data'\n",
        "\n",
        "for folder in os.listdir(data_dir):\n",
        "  folder_path = os.path.join(data_dir, folder)\n",
        "  if os.path.isdir(folder_path):\n",
        "    image_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "    print(f\"Folder: {folder}, Total Images: {image_count}\")"
      ],
      "metadata": {
        "id": "YXfg28SD6X3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "c30-Jpt59Jkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Data"
      ],
      "metadata": {
        "id": "Cfs6Eymt958d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping data that's unnecessary or uncompatible against purpose of the clustering, which are:\n",
        "\n",
        "*   **Terrain compatibility**: Desert\n",
        "*   **Scape purpose**: Grassland, Forest\n",
        "*   **Functional Structure**: Port, Airport, Agriculture, Railway, Highway\n"
      ],
      "metadata": {
        "id": "MBnSsvzb99Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Desert, Grassland, Forest, Port, Airport, Agriculture, Railway, Highway folder form content/data folder\n",
        "folders_to_delete = ['Desert', 'Grassland', 'Forest', 'Port', 'Airport', 'Agriculture', 'Railway', 'Highway']\n",
        "\n",
        "for folder in folders_to_delete:\n",
        "  folder_path = os.path.join(data_dir, folder)\n",
        "  if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Deleted folder: {folder_path}\")\n",
        "  else:\n",
        "    print(f\"Folder not found: {folder_path}\")"
      ],
      "metadata": {
        "id": "8nXcylNx9IRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read remaining data\n",
        "for folder in os.listdir(data_dir):\n",
        "  folder_path = os.path.join(data_dir, folder)\n",
        "  if os.path.isdir(folder_path):\n",
        "    image_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "    print(f\"Folder: {folder}, Total Images: {image_count}\")"
      ],
      "metadata": {
        "id": "1ZJ_s_BiDoTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning and Normalize Images"
      ],
      "metadata": {
        "id": "JxXQ2_u2D1jR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset source says that the data is already clean. Hence, to ensure it's right, this process will check every image.\n",
        "\n",
        "---\n",
        "The **properties** are,\n",
        "* Dimensions: 256x256\n",
        "* Horizontal resolution: 96 dpi\n",
        "* Vertical resolution: 96 dpi\n",
        "* Bit depth: 24\n"
      ],
      "metadata": {
        "id": "230XjEyGD_CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define properties\n",
        "EXPECTED_DIMENSIONS = (256, 256)\n",
        "EXPECTED_HORIZONTAL_RESOLUTION = 96\n",
        "EXPECTED_VERTICAL_RESOLUTION = 96"
      ],
      "metadata": {
        "id": "OA9QdW5YF1NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check every images and print check result\n",
        "def check_image_properties(image_path):\n",
        "  try:\n",
        "    with Image.open(image_path) as img:\n",
        "      # Check dimensions\n",
        "      if img.size != EXPECTED_DIMENSIONS:\n",
        "        return False\n",
        "\n",
        "      # Check resolution (DPI)\n",
        "      dpi = img.info.get('dpi', (0, 0))\n",
        "      if dpi != (0, 0):  # Only check DPI if it's present\n",
        "        if dpi[0] != EXPECTED_HORIZONTAL_RESOLUTION or dpi[1] != EXPECTED_VERTICAL_RESOLUTION:\n",
        "          return False\n",
        "\n",
        "      # Check bit depth (RGB = 24-bit)\n",
        "      if img.mode != 'RGB':\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error checking image {image_path}: {e}\")\n",
        "    return False\n",
        "\n",
        "def check_images_in_folder(folder_path):\n",
        "  different_properties_count = 0\n",
        "  total_images = 0\n",
        "\n",
        "  for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "      if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
        "        image_path = os.path.join(root, file)\n",
        "        total_images += 1\n",
        "        if not check_image_properties(image_path):\n",
        "          different_properties_count += 1\n",
        "\n",
        "  if different_properties_count > 0:\n",
        "    print(f\"Total images with different properties: {different_properties_count}\")\n",
        "  else:\n",
        "    print(\"All images have the correct properties.\")\n",
        "\n",
        "  print(f\"Total images checked: {total_images}\")"
      ],
      "metadata": {
        "id": "ZsZ8Yw9xEUM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_images_in_folder(data_dir)"
      ],
      "metadata": {
        "id": "7pZtrIcEGRzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since all of the image is correct, any other normalizing/cleaning process won't be needed."
      ],
      "metadata": {
        "id": "2vzwCybdKCHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store Data"
      ],
      "metadata": {
        "id": "o9yp3DTRK0Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images to numpy arrays along with labels\n",
        "def convert_to_numpy_with_labels(data_dir):\n",
        "  images = []\n",
        "  labels = []\n",
        "  label_dict = {}\n",
        "  label_counter = 0\n",
        "\n",
        "  for folder_name in os.listdir(data_dir):\n",
        "    folder_path = os.path.join(data_dir, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "      # Assign a unique integer label for each folder (class name)\n",
        "      if folder_name not in label_dict:\n",
        "        label_dict[folder_name] = label_counter\n",
        "        label_counter += 1\n",
        "\n",
        "      # Process each image file in the folder\n",
        "      for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "          img_path = os.path.join(folder_path, filename)\n",
        "          try:\n",
        "            # Load image and convert to numpy array\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img_array = np.array(img)\n",
        "\n",
        "            # Append the image data and its corresponding label\n",
        "            images.append(img_array)\n",
        "            labels.append(label_dict[folder_name])\n",
        "          except Exception as e:\n",
        "            print(f\"Error processing image {img_path}: {e}\")\n",
        "\n",
        "  # Convert lists to numpy arrays\n",
        "  images_np = np.array(images)\n",
        "  labels_np = np.array(labels)\n",
        "\n",
        "  return images_np, labels_np, label_dict"
      ],
      "metadata": {
        "id": "E2mM60icMFT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run convert function\n",
        "images, labels, label_dict = convert_to_numpy_with_labels(data_dir)\n",
        "print(f\"Total images: {len(images)}\")\n",
        "print(f\"Label dictionary: {label_dict}\")"
      ],
      "metadata": {
        "id": "UcMIvVtbOwaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check detail of images\n",
        "def print_total_images_per_label(labels_np, label_dict):\n",
        "    # Get unique labels and their counts\n",
        "    unique_labels, counts = np.unique(labels_np, return_counts=True)\n",
        "\n",
        "    # Invert the label_dict to get class names from integer labels\n",
        "    inverted_label_dict = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    print(\"Total images per label:\")\n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        class_name = inverted_label_dict[label]\n",
        "        print(f\"Label '{class_name}' (ID {label}): {count} images\")\n",
        "\n",
        "print_total_images_per_label(labels, label_dict)"
      ],
      "metadata": {
        "id": "LB5SPjtNOiH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "A3g4VoQ4P-xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image's characteristic that will be considered are:\n",
        "\n",
        "* Plants Area (color)\n",
        "* Construction Area (edges)\n",
        "* Vacant Area (remaining area)\n",
        "\n",
        "The feature take shapes in percentage of each characteristic above."
      ],
      "metadata": {
        "id": "8t8cfxrbEgrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraction Process"
      ],
      "metadata": {
        "id": "dh5lVKA-EDqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for extraction\n",
        "def extract_features(image):\n",
        "  # Convert to HSV for plants detection\n",
        "  hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # Define range for detecting green (plants) in HSV\n",
        "  lower_green = np.array([36, 25, 25])\n",
        "  upper_green = np.array([70, 255, 255])\n",
        "  mask_plants = cv2.inRange(hsv_image, lower_green, upper_green)\n",
        "\n",
        "  # Refine the mask using morphological closing to remove noise\n",
        "  mask_plants = morphology.closing(mask_plants, square(7))\n",
        "\n",
        "  # Construction detection Canny edge detection\n",
        "  gray_image = rgb2gray(image)\n",
        "  edges = canny(gray_image, sigma=1)\n",
        "\n",
        "  # Close the edges to make shapes continuous and fill in gaps\n",
        "  edges_closed = morphology.binary_closing(edges, square(5))\n",
        "\n",
        "  # Label connected regions (contours) in the construction mask\n",
        "  labeled_construction = measure.label(edges_closed)\n",
        "\n",
        "  # Filter out small regions based on area (keep only significant regions)\n",
        "  props = measure.regionprops(labeled_construction)\n",
        "  mask_construction = np.zeros_like(labeled_construction)\n",
        "\n",
        "  for prop in props:\n",
        "    if prop.area > 500:\n",
        "      mask_construction[labeled_construction == prop.label] = 255\n",
        "\n",
        "  # Vacant space: regions that are neither construction nor plants\n",
        "  mask_vacant = np.logical_not(np.logical_or(mask_plants, mask_construction))\n",
        "\n",
        "  # Label vacant space regions\n",
        "  labeled_vacant = measure.label(mask_vacant)\n",
        "  props_vacant = measure.regionprops(labeled_vacant)\n",
        "\n",
        "  # Filter out small vacant areas based on area\n",
        "  mask_large_vacant = np.zeros_like(mask_vacant, dtype=np.uint8)\n",
        "  for prop in props_vacant:\n",
        "    if prop.area > 500:  # Adjust the area threshold for vacant spaces\n",
        "      mask_large_vacant[labeled_vacant == prop.label] = 255\n",
        "\n",
        "  # Calculate percentages of each feature\n",
        "  total_pixels = image.shape[0] * image.shape[1]\n",
        "  percent_plants = np.sum(mask_plants > 0) / total_pixels * 100\n",
        "  percent_construction = np.sum(mask_construction > 0) / total_pixels * 100\n",
        "  percent_vacant = np.sum(mask_large_vacant > 0) / total_pixels * 100\n",
        "\n",
        "  # Return the feature vector\n",
        "  return [percent_vacant, percent_plants, percent_construction]"
      ],
      "metadata": {
        "id": "l0rjlOMjQCqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run extraction for all images\n",
        "features = []\n",
        "for image in images:\n",
        "  features.append(extract_features(image))\n",
        "\n",
        "features = np.array(features)"
      ],
      "metadata": {
        "id": "583SzwjmG12O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Visualization"
      ],
      "metadata": {
        "id": "pm1Z5GvTF7Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for feature visualization\n",
        "def visualize_features(image, label, label_name):\n",
        "  # Extract the masks using the same method as in feature extraction\n",
        "  hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "  lower_green = np.array([30, 40, 40])\n",
        "  upper_green = np.array([90, 255, 255])\n",
        "  mask_plants = cv2.inRange(hsv_image, lower_green, upper_green)\n",
        "  mask_plants = morphology.closing(mask_plants, square(7))\n",
        "\n",
        "  gray_image = rgb2gray(image)\n",
        "  edges = canny(gray_image, sigma=1)\n",
        "  edges_closed = morphology.binary_closing(edges, square(5))\n",
        "\n",
        "  labeled_construction = measure.label(edges_closed)\n",
        "  props = measure.regionprops(labeled_construction)\n",
        "  mask_construction = np.zeros_like(labeled_construction)\n",
        "  for prop in props:\n",
        "    if prop.area > 500:\n",
        "      mask_construction[labeled_construction == prop.label] = 255\n",
        "\n",
        "  mask_vacant = np.logical_not(np.logical_or(mask_plants, mask_construction))\n",
        "  labeled_vacant = measure.label(mask_vacant)\n",
        "  props_vacant = measure.regionprops(labeled_vacant)\n",
        "  mask_large_vacant = np.zeros_like(mask_vacant, dtype=np.uint8)\n",
        "  for prop in props_vacant:\n",
        "    if prop.area > 500:\n",
        "      mask_large_vacant[labeled_vacant == prop.label] = 255\n",
        "\n",
        "  # Display the original image and masks\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  plt.subplot(1, 4, 1)\n",
        "  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "  plt.title(f\"Original Image: {label_name}\")\n",
        "\n",
        "  plt.subplot(1, 4, 2)\n",
        "  plt.imshow(mask_plants, cmap='Greens')\n",
        "  plt.title(\"Plants Mask\")\n",
        "\n",
        "  plt.subplot(1, 4, 3)\n",
        "  plt.imshow(mask_construction, cmap='gray')\n",
        "  plt.title(\"Construction Mask\")\n",
        "\n",
        "  plt.subplot(1, 4, 4)\n",
        "  plt.imshow(mask_large_vacant, cmap='Blues')\n",
        "  plt.title(\"Vacant Space Mask\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TanQVgG2F6Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run visualization\n",
        "for label_name, label_idx in label_dict.items():\n",
        "  image_indices = np.where(labels == label_idx)[0]\n",
        "\n",
        "  if len(image_indices) > 0:\n",
        "    image_idx = image_indices[0]\n",
        "    image = images[image_idx]\n",
        "    visualize_features(image, label_idx, label_name)\n",
        "  else:\n",
        "    print(f\"No images found for label '{label_name}' (index {label_idx}).\")"
      ],
      "metadata": {
        "id": "Vbk4ePYkGDFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "O8vZ74l8Kx32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KMeans"
      ],
      "metadata": {
        "id": "WwNgSdfMK154"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KMeans Clustering function with 3D Plot and original labels coloring\n",
        "def cluster_kmeans_3d(features, labels, label_dict, n_clusters=4):\n",
        "    # Fit the KMeans model\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans = kmeans.fit_predict(features)\n",
        "\n",
        "    # Prepare the 3D scatter plot\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Use the original image labels for coloring\n",
        "    unique_labels = np.unique(labels)\n",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "    # Get the keys (label names) that correspond to the values in labels\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        idx = np.where(labels == label)\n",
        "\n",
        "        # Find the label name by looking up the value in label_dict\n",
        "        label_name = [key for key, val in label_dict.items() if val == label]\n",
        "\n",
        "        if label_name:  # If the label name exists\n",
        "            ax.scatter(features[idx, 0], features[idx, 1], features[idx, 2], color=colors[i], label=label_name[0])\n",
        "        else:\n",
        "            print(f\"Warning: Label {label} not found in label_dict\")\n",
        "\n",
        "    ax.set_xlabel('Percent Vacant')\n",
        "    ax.set_ylabel('Percent Plants')\n",
        "    ax.set_zlabel('Percent Construction')\n",
        "    ax.set_title('KMeans Clustering (3D)')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the number of labels in each cluster\n",
        "    count_labels = Counter(kmeans)\n",
        "    print(\"KMeans Cluster Counts:\")\n",
        "    for cluster, count in count_labels.items():\n",
        "        print(f\"Cluster {cluster}: {count} images\")\n",
        "\n",
        "    return kmeans"
      ],
      "metadata": {
        "id": "T-_obZKOK6LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans and visualize\n",
        "kmeans = cluster_kmeans_3d(features, labels, label_dict)"
      ],
      "metadata": {
        "id": "hDuhxjqAQQRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Model"
      ],
      "metadata": {
        "id": "FriAACIoSapD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(kmeans, '/content/kmeans_model.pkl')\n",
        "print(\"KMeans model saved as: kmeans_model.pkl\")"
      ],
      "metadata": {
        "id": "TYCeUGlQScm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}